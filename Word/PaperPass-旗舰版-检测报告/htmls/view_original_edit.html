<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="keywords" content="">
    <meta name="description" content="">
    <title>修改文档</title>
    <link href="css/bootstrap.css" rel="stylesheet" />
    <link href="css/style.css" rel="stylesheet" />
</head>
<body>
<div class="bg-grey PLR40">

    <div class="paper-txt P30 PB0">
        <div class="alert alert-success" role="alert">此为您在“详细报告”中修改后临时保存的内容，编辑过的内容会变绿色</div>
        <p class="text-idt25" data-id="1">本科生毕业设计[论文]</p><p class="text-idt25" data-id="2">基于工业大数据的生产设备故障诊断</p><p class="text-idt25" data-id="3">院 系</p><p class="text-idt25" data-id="4">机械科学与工程学院</p><p class="text-idt25" data-id="5">专业班级</p><p class="text-idt25" data-id="6">机械1401班</p><p class="text-idt25" data-id="7">姓 名</p><p class="text-idt25" data-id="8">张照博</p><p class="text-idt25" data-id="9">学 号</p><p class="text-idt25" data-id="10">U201410606</p><p class="text-idt25" data-id="11">指导教师</p><p class="text-idt25" data-id="12">金海、吴波</p><p class="text-idt25" data-id="13">年 月 日</p><p class="text-idt25" data-id="14">学位论文原创性声明</p><p class="text-idt25" data-id="15">（黑体小2号加粗居中）</p><p class="text-idt25" data-id="16">本人郑重声明：所呈交的论文是本人在导师的指导下独立进行研究所取得的研究成果。除了文中特别加以标注引用的内容外，本论文不包括任何其他个人或集体已经发表或撰写的成果作品。本人完全意识到本声明的法律后果由本人承担。</p><p class="text-idt25" data-id="17">（宋体小4号）</p><p class="text-idt25" data-id="18">作者签名： 年 月 日</p><p class="text-idt25" data-id="19">学位论文版权使用授权书</p><p class="text-idt25" data-id="20">（黑体小2号加粗居中）</p><p class="text-idt25" data-id="21">本学位论文作者完全了解学校有关保障、使用学位论文的规定，同意学校保留并向有关学位论文管理部门或机构送交论文的复印件和电子版，允许论文被查阅和借阅。本人授权省级优秀学士论文评选机构将本学位论文的全部或部分内容编入有关数据进行检索，可以采用影印、缩印或扫描等复制手段保存和汇编本学位论文。</p><p class="text-idt25" data-id="22">本学位论文属于 1、保密囗，在 年解密后适用本授权书</p><p class="text-idt25" data-id="23">2、不保密囗 。</p><p class="text-idt25" data-id="24">（请在以上相应方框内打）</p><p class="text-idt25" data-id="25">（宋体小4号）</p><p class="text-idt25" data-id="26">作者签名： 年 月 日</p><p class="text-idt25" data-id="27">导师签名： 年 月 日</p><p class="text-idt25" data-id="28">(注：此页内容装订在论文扉页)摘 要</p><p class="text-idt25" data-id="29">由于计算机硬件以符合摩尔定律的速度迅猛发展，计算机数据存储、数据传输和分布式计算的成本都大幅度降低。而现代化的工厂中，往往都布置有大量的传感器，而且随着存储成本的降低，读取到的设备信息变得更加丰富，由此便会产生海量的工业数据。</p><p class="text-idt25" data-id="30">对于这一变化，全世界许多国家都相继提出相应的举措。最初是德国提出了工业4.0的概念，之后美国推出工业互联网，我国也相继推出中国制造2025的概念，其核心都指向智能制造。而工业大数据技术则是这些内容中的核心部分。</p><p class="text-idt25" data-id="31">在工业设备的运行过程中，自然磨损、设备超载、操作不当等多种原因会导致设备的性能发生下降，甚至于产生故障或者是异常。而通过对设备加装传感器进行监控，获取到设备的实时信息并且加以梳理计算，就可以得到设备各个部位的实时运行状态，从而实现对设备的监控。而如果出现了设备故障现象，则可以通过对历史数据进行数据挖掘、清洗形成故障模型，导入设备的最新运行数据进行故障诊断。</p><p class="text-idt25" data-id="32">设备的故障诊断方法可以分为三种:基于机理模型的方法，基于数据驱动的方法，基于知识工程的方法[1]。本文将采用基于数据驱动的方法中的基于分类的方法进行故障模型的构建。同时为了对比不同分类方法的性能，本文采用了两种分类方式进行比较。</p><p class="text-idt25" data-id="33">本文主要研究工作和成果如下：</p><p class="text-idt25" data-id="34">（1）建立了以决策树算法为基础的故障诊断模型；</p><p class="text-idt25" data-id="35">（2）实现了以支持向量机为核心的数据驱动方法。对支持向量机的核心原理进行了研究，以风力涡轮机齿轮箱的健康数据、故障数据进行了SVM的分类检测，实现了简单的故障诊断；</p><p class="text-idt25" data-id="36">（3）比对了两种策略的精度以及其他的一些的性能度量。</p><p class="text-idt25" data-id="37">关键词：故障诊断；工业大数据；数据驱动；决策树；支持向量机</p><p class="text-idt25" data-id="38">Abstract</p><p class="text-idt25" data-id="39">As the computer hardware rapidly develops at a rate consistent with Moore’s Law， the cost of computer data storage， data transmission， and distributed computing has been greatly reduced. In the modern factories， a large number of sensors are often arranged， and as the cost of storage decreases， the read device information becomes more abundant， and thus a large amount of industrial data will be generated.</p><p class="text-idt25" data-id="40">For this change， many countries around the world have put forward corresponding measures in succession. Initially， Germany proposed the concept of ”Industry 4.0”. After the United States introduced the ”Industrial Internet，” China has also successively introduced the concept of ”Made in China 2025.” Its core points to intelligent manufacturing. Industrial big data technology is a core part of these contents.</p><p class="text-idt25" data-id="41"> During the operation of industrial equipment， natural wear， equipment overload， improper operation， and other reasons can cause the performance of the equipment to drop， and even result in failure or abnormality. By adding sensors to the equipment for monitoring， obtaining real- time information from the equipment and combing calculations， the real- time running status of various parts of the equipment can be obtained， thereby realizing the monitoring of the equipment. If there is a device failure， you can perform data mining and cleaning on the historical data to form a fault model and import the latest operating data of the device for fault diagnosis.</p><p class="text-idt25" data-id="42">Currently， there are three types of device diagnostic methods that are popular in the world: mechanistic model-based methods， Data-Driven methods， and knowledge-based methods. This article will use a classification-based approach based on a Data-Driven approach to build a fault model. At the same time， in order to compare the performance of different classification methods， this paper uses two classification methods to compare.</p><p class="text-idt25" data-id="43">The main research work and achievements of this article are as follows:</p><p class="text-idt25" data-id="44">(1) Establish a fault diagnosis model based on decision tree algorithm， and study the differences between ID3 and C4.5;</p><p class="text-idt25" data-id="45">(2) A Data-Driven approach based on Support Vector Machines(SVM) is implemented. The core principle of SVM is studied. The classification and detection of SVM is performed based on the health data and fault data of the wind turbine gearbox， and a simple fault diagnosis is realized.</p><p class="text-idt25" data-id="46">(3) Compare the running time of two strategies， the accuracy rate of fault diagnosis， and some other performance metrics.</p><p class="text-idt25" data-id="47">Key Words：Fault Diagnosis; Industrial Big Data; Data-Driven Method; Decision Tree; Support Vector Machine</p><p class="text-idt25" data-id="48">目录</p><p class="text-idt25" data-id="49">摘 要I</p><p class="text-idt25" data-id="50">AbstractII</p><p class="text-idt25" data-id="51">1 绪论1</p><p class="text-idt25" data-id="52">1.1 选题背景和意义1</p><p class="text-idt25" data-id="53">1.2 国内外研究现况及发展趋势2</p><p class="text-idt25" data-id="54">1.2.1 国内研究现状2</p><p class="text-idt25" data-id="55">1.2.2 国外研究现状2</p><p class="text-idt25" data-id="56">1.3 主要研究内容3</p><p class="text-idt25" data-id="57">2 故障诊断的总体设计方案4</p><p class="text-idt25" data-id="58">2.1 故障模型的要求4</p><p class="text-idt25" data-id="59">2.2 决策树建立故障树模型4</p><p class="text-idt25" data-id="60">2.2.1 信息熵4</p><p class="text-idt25" data-id="61">2.2.2 信息增益5</p><p class="text-idt25" data-id="62">2.2.3 ID3算法5</p><p class="text-idt25" data-id="63">2.3 支持向量机二分类原理8</p><p class="text-idt25" data-id="64">2.3.1 SVM原理8</p><p class="text-idt25" data-id="65">2.3.2 对偶问题11</p><p class="text-idt25" data-id="66">2.3.3 SVM核函数12</p><p class="text-idt25" data-id="67">3 具体方案设计16</p><p class="text-idt25" data-id="68">3.1 数据获取16</p><p class="text-idt25" data-id="69">3. 数据存取17</p><p class="text-idt25" data-id="70">3.3 决策树实现19</p><p class="text-idt25" data-id="71">3.3.1 连续属性值离散化19</p><p class="text-idt25" data-id="72">3.3.2 样本初始化23</p><p class="text-idt25" data-id="73">3.3.3 生成决策树24</p><p class="text-idt25" data-id="74">3.3.4 数据测试类28</p><p class="text-idt25" data-id="75">3.4 支持向量机实现30</p><p class="text-idt25" data-id="76">3.5 人机交互界面设计31</p><p class="text-idt25" data-id="77">3.5.1 界面组件介绍32</p><p class="text-idt25" data-id="78">3.5.2 操作命令介绍34</p><p class="text-idt25" data-id="79">3.5.3 适用场景35</p><p class="text-idt25" data-id="80">4 性能分析37</p><p class="text-idt25" data-id="81">4.1 性能度量37</p><p class="text-idt25" data-id="82">4.2 决策树性能度量38</p><p class="text-idt25" data-id="83">4.3 支持向量机性能度量40</p><p class="text-idt25" data-id="84">5 结论41</p><p class="text-idt25" data-id="85">5.1 全文总结41</p><p class="text-idt25" data-id="86">5.2 展望42</p><p class="text-idt25" data-id="87">致谢43</p><p class="text-idt25" data-id="88">参考文献44</p><p class="text-idt25" data-id="89">附录46</p><p class="text-idt25" data-id="90">1 绪论</p><p class="text-idt25" data-id="91">1.1 选题背景和意义</p><p class="text-idt25" data-id="92">在计算机行业还未能发展到如今这般规模的时候，人们只能选择抽样的数据、局部的数据和片面的数据，纯粹靠经验、理论、假设和价值观去发现、理解未知领域的规律。而这样做的结果，就是对真实现象的抽象归纳与演绎推理，这就不可避免的包含了各种主观上的因素。同时由于样本的局部性，很多推理归纳出来的结果与实际现象具有极大的偏差。</p><p class="text-idt25" data-id="93">而如今的所谓大数据，通常都指数据量在太字节（TB）即2的40次方以上，一般情况下难以收集、存储、管理以及分析的数据。而且随着科技进步，大数据对于大的含义还在不断地刷新。但是大数据不仅仅只关乎于数据量的大小，而且还与其他的因素有着千丝万缕的关系。</p><p class="text-idt25" data-id="94">大数据其真正的意义在于：我们可以通过各式各样的传感器，实现与真实世界更加紧密、准确的连接。在得到实时数据后进行整合、挖掘、云计算，去逐步的逼近真实世界，挖掘出那些未曾被我们发现的隐藏规律，建立更加符合真实的数学模型，这是大数据的魅力所在。而在大数据的庞大篇幅中，工业大数据占据着重要地位。工业大数据是智能制造的关键技术，主要作用是打通物理世界和信息世界，推动生产型制造向服务型制造转型[2]。</p><p class="text-idt25" data-id="95">而在工业领域，工业大数据的一大发展方向就是故障诊断，数据的产生和记录贯穿于一台设备从投入生产到损耗的全过程，而通过一定数量的智能传感器，我们可以监控某些生产设备的所有信息，使设备在生产线的实时状态远程监控成为可能，这一方面改善了工作人员的工作环境，另一个更为重要的方面就是提高了设备发生故障或者异常时候的反应速度以及排除故障的效率。</p><p class="text-idt25" data-id="96">伴随着工业生产水平发展的突飞猛进，工业设备精度越来越高，结构越来越复杂，所以在车间内很多设备的故障都未能得到及时的发现和解决，这一点很容易对工厂造成巨大的损失.由于设备愈加复杂所导致的设备故障信息数据呈现指数型增长，而运行时所产生的海量数据，采用传统基于机理模型的方式已经很难负载如此巨量规模的数据分析，进行故障诊断了。</p><p class="text-idt25" data-id="97">此外，工业设备结构极其复杂，不同模块之间可能会产生故障的交集，人工分析或者是传统的先验知识故障检测手段已经无法准确、迅速的完成故障的诊断。因此，结合工业大数据对工业设备所产生的海量数据进行数据挖掘分析建立故障诊断模型，对于提高设备维护效率、迅速有效解决故障、降低维修费用有巨大意义。</p><p class="text-idt25" data-id="98">1.2 国内外研究现况及发展趋势</p><p class="text-idt25" data-id="99">1.2.1 国内研究现状</p><p class="text-idt25" data-id="100">金风科技股份有限公司基于大量风场的历史故障信息进行大数据分析，对 SCADA( Supervisory Control and Data Acquisition，监控和数据采集系统)瞬时数据的时间序列模式提取，挖掘桨距角一致性、变桨过程曲线模态、振动模式、变桨电机温差、 ng5充电电流差异等断裂征兆模式，通过多模型融合和深度学习，提前90 h进行断裂预警，通过预防性维修消除重大故障隐患[3]。张鹏在在线性模型的基础上进行了大量改进，提出了将卡尔曼滤波器和基于非线性模型相结合的方法，并在航空发动机与传感器上进行了验证[4]。徐德民等人以航行器为研究对象，使用连续-离散无迹卡尔曼滤波算法对航行器执行器进行故障诊断[5]。南京航空航天大学鲁峰等人对发动机进行了仿真建模并且获得了影响系数矩阵，成功实现了对发动机中的气路故障进行诊断[6]。</p><p class="text-idt25" data-id="101">1.2.2 国外研究现状</p><p class="text-idt25" data-id="102">国际权威专家 Frank 将故障诊断的方法总结为三种:基于机理模型的方法、基于数据驱动的方法、基于知识工程的方法[7] 。葡萄牙科英布拉大学的Marco S. Reis教授和Geert Gins在《Industrial Process Monitoring in the Big Data/Industry 4.0 Era: From Detection， to Diagnosis， to Prognosis》一文中提到，过去的重点都是检测，也就是基于机理模型的一种对比当前数据的检测办法，实现高水平的检测速度和强度是过去 IPM研究的主要重点。在处理新流程时，这是一个必要的步骤，但是随着时间推进，越来越多的因素阻碍了更先进的监控手段的发展[8]。因此为了解决这些障碍与挑战，我们需要找到一种方法可以找到故障根源，也就是我们当今时代的主流过程监测手段：故障诊断。未来的发展方向更是令人心驰神往，故障预检测，能够根据当前的运行数据获取未来一段时间内的设备运行状态预测。</p><p class="text-idt25" data-id="103">瑞典吕勒奥理工大学的 Lianwei Zhang开发除了一套专用于大数据检测以及维护的系统以及一种基于自适应核密度的异常检测（ Adaptive- KD）方法，在工业场景中具有极大的使用价值。</p><p class="text-idt25" data-id="104">1.3 主要研究内容</p><p class="text-idt25" data-id="105">（1） 研究数据挖掘算法，采集数据进行模型构建，并且根据新的数据进行模型改进、重构；</p><p class="text-idt25" data-id="106">（2） 研究关联度计算算法，对故障数据进行适当处理，提高最后得到的故障模型的精度；</p><p class="text-idt25" data-id="107">（3） 研究机器设备的属性之间的联系，有效的剔除一些对模型精度无益的内容，提高运行效率；</p><p class="text-idt25" data-id="108">（4） 研究模型的改进方案，如决策树中的剪枝方法、连续之离散化算法，对模型进行精简，减少模型构建所消耗的资源。</p><p class="text-idt25" data-id="109">2 故障诊断的总体设计方案</p><p class="text-idt25" data-id="110">2.1 故障模型的要求</p><p class="text-idt25" data-id="111">故障模型应该是基于历史数据构建的，由于我们的模型是基于数据驱动，所以对于机械设备方面的先验知识需求量远小于基于机理模型和基于知识工程的构建方式。另外，我们的模型要能接受新的运行数据，对于数据进行测试，从而进行故障诊断的最终目的。</p><p class="text-idt25" data-id="112">在精度上，模型的精度应该随着数据的不断完善而改进，构建模型所使用的数据越多，那么我们的模型的泛化程度就越高，对于各种实际情况的解读能力就会进一步提升。另外故障模型的基础是基于工业大数据，对于工业大数据的各个环节都会在具体实现环节中一一对应。</p><p class="text-idt25" data-id="113">图1 工业大数据技术架构</p><p class="text-idt25" data-id="114">2.2 决策树建立故障树模型</p><p class="text-idt25" data-id="115">2.2.1 信息熵</p><p class="text-idt25" data-id="116">假设当前样本集 D中有 N个样本，而整个样本有 k个分类，每个分类对应的样本数量为那么对于每个分类，他们各自占据的信息量（也可以理解为样本分类的频率）为：</p><p class="text-idt25" data-id="117">结合每一个分类的信息量，则此样本总体的信息熵为：</p><p class="text-idt25" data-id="118">2.2.2 信息增益</p><p class="text-idt25" data-id="119">假设当前样本集D中有N 个样本，每个样本都有一些属性，假设我们目前取属性A作为我们计算信息增益的属性。</p><p class="text-idt25" data-id="120">根据属性 A，我们可以属性 A的不同取值（假设有 v种），将整个样本集 D分为 v个子样本集，每个样本子集的样本数为 N，那么每一个样本子集的频率为：</p><p class="text-idt25" data-id="121">那么该样本集的A属性的信息增益即为：</p><p class="text-idt25" data-id="122">2.2.3 ID3算法</p><p class="text-idt25" data-id="123">ID3是一种以自顶向下递归的方法构造决策树的贪心算法。其决策树的基本生成策略如下:</p><p class="text-idt25" data-id="124">（1）树以整体样本作为单个节点开始；</p><p class="text-idt25" data-id="125">（2）如果当前节点中，所有的样本都属于同一类，则该节点成为叶节点，并标记为当前样本的类；</p><p class="text-idt25" data-id="126">（3）否则，使用前面提到的信息增益作为判断信息，选择信息增益最大的一个属性作，该各个属性值将成为该节点往下进行分支的依据。在这里，我们假设所有的属性都是分类的，即取离散值，连续值的属性必须离散化[9]；</p><p class="text-idt25" data-id="127">（4） 对测试属性的每个已知的值创建一个分支，并据此划分样本子集；</p><p class="text-idt25" data-id="128">（5） 算法使用类似的方法，递归地形成每个划分上的样本决策树。一旦一个属性出现在一个节点上，就不必在该节点的后代上考虑这个属性。</p><p class="text-idt25" data-id="129">ID3算法虽然简单易用，但是也有很多缺陷：</p><p class="text-idt25" data-id="130">（1） ID3算法缺乏对于连续值的处理手段，而在现实生活中，很多的应用环境都是采集到的连续值；</p><p class="text-idt25" data-id="131">（2）计算信息增益的时候对于样本频率P(xi)有极大的依赖性，有时候会对模型造成很大的偏差；</p><p class="text-idt25" data-id="132">（3）对噪声较为敏感，所谓噪声也就是一些在生成模型的时候就给定的错误数据；</p><p class="text-idt25" data-id="133">（4）采用递归的方式形成模型，而且整个决策树的生成过程对于数据多次读取存写，所以算法较为低效，而且无法应用于大数据量的场合下。</p><p class="text-idt25" data-id="134">下面是利用这些概念获得故障树的过程：</p><p class="text-idt25" data-id="135">图2 ID3算法生成决策树流程图</p><p class="text-idt25" data-id="136">为了提高决策树的模型精度，去除掉模型创建时一些错误数据的干扰，有两种剪枝方法可以用于提高决策树的正确分类能力：</p><p class="text-idt25" data-id="137">（1）预剪枝方法(prepruning)，该方法通过提前停止树的向下延伸而对树剪枝。在各个节点向下分支之前，判断通往该分支的样本子集中的判断正确率进行对比，如果在当前节点的正确率高于分支后的子节点，那么就停止生长，这就是预剪枝的主要思想。该方法很多的分支都未曾展开，降低了过拟合的风险，而且还显著减少了决策树的训练时间和花销；但是另外一方面，一些分支虽然不能提升整体的泛化性能，但是由其再次展开的分支却有可能导致性能显著提高，而且预剪枝的贪心本质给这种方法带来了欠拟合的风险。</p><p class="text-idt25" data-id="138">（2）后剪枝方法( postpruning)，顾名思义，该方法是预先生成一颗完整的决策树，然后从每一个叶节点往上查看父节点，计算如果该父节点进行剪枝成为叶节点后是否会提高判定精度来决定是否剪枝。这种方式直到无法提高决策树性能为止。对比预剪枝方法，后剪枝方法保留了更多的分支。一般情况下，后剪枝方法的欠拟合风险比较小，泛化性能优于预剪枝方法生成的决策树。但是由于后剪枝方法是在决策树生成后在进行的，所以在训练时间和花销上会比预剪枝方法高得多。</p><p class="text-idt25" data-id="139">2.3 支持向量机二分类原理</p><p class="text-idt25" data-id="140">2.3.1 SVM原理</p><p class="text-idt25" data-id="141">支持向量机（ Support Vector Machine， SVM）是一种经典的二分类模型算法，基本模型定义为特征空间中最大间隔的线性分类器，其学习的优化目标便是间隔最大化，因此支持向量机本身可以转化为一个凸二次规划求解的问题。</p><p class="text-idt25" data-id="142">对于二分类学习器，假设数据是线性可分的，这时分类学习就是找到一个合适的超平面来进行分类，该超平面能够将不同类别的样本分开，下图中的点是低维数据表示，而这些数据对应的超平面就是中间那根线。对于点来说，线毫无疑问是处于高维的超平面了。随着维数增加，超平面总是比数据的维数多一维。</p><p class="text-idt25" data-id="143">图3 二维超平面</p><p class="text-idt25" data-id="144">但是这样的超平面可能存在多个，我们应该寻找的最优超平面该如何获取呢？</p><p class="text-idt25" data-id="145">图4 存在多个划分超平面将两类训练样本分开</p><p class="text-idt25" data-id="146">直观上看的话，我们应该寻找位于两类训练样本正中间的超平面作为我们的最优超平面，因为这个超平面对于整个训练样本局部扰动的容忍性能最好。换言之，这个超平面所产生的分类结果是最鲁棒的，对于未知的数据的分类能里最强。</p><p class="text-idt25" data-id="147">在样本空间中，超平面可以通过如下线性方程表示：</p><p class="text-idt25" data-id="148">其中w = （w1;w2;w3;...;wd）为超平面的法向量，决定了超平面的方向。b为位移，决定了超平面与原点之间的距离。既然有了可以用数学方式表达的超平面，那么样本空间中任意一点到超平面的距离也就可以表示为：</p><p class="text-idt25" data-id="149">假设超平面能够正确分类，即对于，则有:</p><p class="text-idt25" data-id="150">那么我们可以得到距离超平面最近的几个训练样本可以使得上式中的等号成立，这几个样本就称为支持向量，两个异类支持向量到超平面的距离之和为：</p><p class="text-idt25" data-id="151">这个距离就被称作间隔（margin）：</p><p class="text-idt25" data-id="152">图5 支持向量与间隔</p><p class="text-idt25" data-id="153">显而易见的，我们的目标就是找到具有最大间隔的超平面作为最优超平面。那么此超平面需要符合下列特点：</p><p class="text-idt25" data-id="154">由此，为了得到最大间隔下的最优超平面，只需要最小化，于是，上式可以改写为：</p><p class="text-idt25" data-id="155">这就是支持向量机（Support Vector Machine，SVM）这一方法的基本型。</p><p class="text-idt25" data-id="156">2.3.2 对偶问题</p><p class="text-idt25" data-id="157">由上面的支持向量机方法的基本型，我们可以知道这是一个带约束的凸二次规划问题，解决这个问题的较高效的办法是：对偶问题（dual problem）。</p><p class="text-idt25" data-id="158">具体的解决方式为给每条约束添加拉格朗日乘子 则上述问题的朗格朗日函数可写为：</p><p class="text-idt25" data-id="159">其中，由拉格朗日乘数法的思想，令对的偏导为0可以的得到：</p><p class="text-idt25" data-id="160">利用两个式子代入到中可以消去，就得到了关于基本型的对偶问题：</p><p class="text-idt25" data-id="161">通过求解出的，我们可以计算得出，从而得到最终具体的模型：</p><p class="text-idt25" data-id="162">在上述的解答过程中，因为基本型有着不等式的约束条件，所以需要满足KKT（Karush-Kuhn-Tucker）条件：</p><p class="text-idt25" data-id="163">于是对于任何的训练样本，都要有 = 0 或者 的限制条件。且必须是满足的样本才会出现在最大间隔边界上，说明这一个样本是支持向量。这一点也就代表着，训练完成后大部分的训练样本都不需要进行保留，只需要留下支持向量的那些样本即可。因为非支持向量的都等于0，去除之后不会对模型产生什么影响。</p><p class="text-idt25" data-id="164">模型建立完毕之后，在对新的数据点进行分类时，实际上就是将这个新的数据点代入到分类函数中，若 f( x)得出来的结果大于0，则为正类，否则为负类。</p><p class="text-idt25" data-id="165">2.3.3 SVM核函数</p><p class="text-idt25" data-id="166">假如训练样本线性不可分，放到我们最开始的例子里面的意思就是：我们无法用一条直线将所有的样本正确分类为两类。如下面的异或问题：</p><p class="text-idt25" data-id="167">图6 异或问题</p><p class="text-idt25" data-id="168">图7 非线性映射</p><p class="text-idt25" data-id="169">对于这种情况，我们可以将原始空间的训练样本映射到一个更高维度的特征空间，使得样本在这个特征空间内线性可分[10]。</p><p class="text-idt25" data-id="170">令表示将x映射到高维空间中的特征向量，那么对比前面线性可分的模型表示，可以得到相应的模型为：</p><p class="text-idt25" data-id="171">同理可得：</p><p class="text-idt25" data-id="172">同样可以得到他的对偶问题，如下：</p><p class="text-idt25" data-id="173">映射后的特征空间维数可能会很高，会极大地加大我们训练时间和内存开销，直接计算 不一定可行。为了避开这个不稳定的区域，我们可以假设存在这样一个函数：</p><p class="text-idt25" data-id="174">即在高维特征空间中映射向量的内积等于在原始样本空间中通过核函数计算后的结果。这就是核技巧。上述式子可以改写为：</p><p class="text-idt25" data-id="175">求解之后可以得到：</p><p class="text-idt25" data-id="176">在线性不可分的情况中，核函数的选择是影响SVM模型的性能至关重要的因素。在明确特征映射的形式之前，我们并不知道具体选择哪一种核函数，而且核函数的选择也隐式的定义了特征空间。如果在模型的构建过程中选择了错误的核函数，那么由此建立的支持向量机模型的性能将会下降许多。</p><p class="text-idt25" data-id="177">下列几种常用的核函数：</p><p class="text-idt25" data-id="178">表2-1 常用核函数表达式及其参数说明</p><p class="text-idt25" data-id="179">名称</p><p class="text-idt25" data-id="180">表达式</p><p class="text-idt25" data-id="181">参数</p><p class="text-idt25" data-id="182">线性核</p><p class="text-idt25" data-id="183">多项式核</p><p class="text-idt25" data-id="184">为多项式的次数</p><p class="text-idt25" data-id="185">高斯核</p><p class="text-idt25" data-id="186">为高斯核的带宽</p><p class="text-idt25" data-id="187">拉普拉斯核</p><p class="text-idt25" data-id="188">SIGMOD核</p><p class="text-idt25" data-id="189">Tanh 为双曲正切函数</p><p class="text-idt25" data-id="190">此外，函数相互组合也可以得到核函数：</p><p class="text-idt25" data-id="191">如果 和 都是核函数，那么对于任意正数其线性组合：</p><p class="text-idt25" data-id="192">也是一个核函数;</p><p class="text-idt25" data-id="193">如果 和 都是核函数，那么核函数的直积：</p><p class="text-idt25" data-id="194">也是一个核函数;</p><p class="text-idt25" data-id="195">如果 是一个核函数，那么对于任意函数g(x):</p><p class="text-idt25" data-id="196">也是一个核函数。</p><p class="text-idt25" data-id="197">3 具体方案设计</p><p class="text-idt25" data-id="198">3.1 数据获取</p><p class="text-idt25" data-id="199">目前主要的数据获取手段是通过互联网上的共享数据集，当前已经获得的数据集合有两个：</p><p class="text-idt25" data-id="200">一个是来自罗马的一家通信科学研究所：Semeion Research Center of Sciences of Communication</p><p class="text-idt25" data-id="201">该数据主要用于测试模型，数据特性如下：</p><p class="text-idt25" data-id="202">图8 钢板数据集属性</p><p class="text-idt25" data-id="203">第二个数据集来自Github上一个Fault Diagnosis项目的自带的风力涡轮内部齿轮箱数据集。该Github项目地址为：Gearboxdata/Gear-Box-Fault-Diagnosis-Data-Set</p><p class="text-idt25" data-id="204">该数据集内的数据分为两类，即正常运行数据和故障状态下的数据。每一类数据下又按照0-90的不同载荷百分比，每10个百分点负载一个层次分为10种运行状态。合共20个文件，一共2021119条记录，每条记录包括载荷百分比在内一共5个属性。</p><p class="text-idt25" data-id="205">图9 风力涡轮齿轮箱数据集属性</p><p class="text-idt25" data-id="206">这些数据虽然是连续性的，但是经过一定的修改，比如固定为小数点后一位精度，这样可以很轻易的将其离散化，虽然对于精度有一定的影响，但是为了是的数据更为集中，不会出现一条数据记录就是一个分支的情况，离散化势在必行。而且后期新增了基于信息熵的离散化功能，可以很方便的进行区间划分从而提高预测的准确率。</p><p class="text-idt25" data-id="207">数据整理我采用的是C++编码来实现的，因为C++对于数据读取有较好的速度支持，而且格式化能力也比较完善。主要的代码如下(GearData.cpp)：</p><p class="text-idt25" data-id="208">for (int i = 0; i [ 10; ++i) {  file=”/Users/zhangzhaobo/Documents/Graduation-Design/Data/BrokenTooth Data/b30hz”+hz[i]+”.txt”;  ifstream in(file);  while(in]]data[0])  {  out[[setprecision(2)[[data[0][[”\t\t”;  for (int i = 1; i [ 4; ++i)  {  in]]data[i];  out[[setprecision(2)[[data[i][[”\t\t”;  }  out[[endl;  }  cout[[file[[” is done!”[[endl;  in.close(); }</p><p class="text-idt25" data-id="209">3. 数据存取</p><p class="text-idt25" data-id="210">如此大量的数据，采用文本读取这种方式很容易出现错误，所以结合数据库知识，最终选定了Mysql数据库作为工业大数据架构的数据存储层。</p><p class="text-idt25" data-id="211">在安装好Mysql之后，建立Graduation_Design数据库，在其中建立了gear表格作为风力涡轮齿轮箱数据的存储表。表格信息如下：</p><p class="text-idt25" data-id="212">mysql] show columns from gear;</p><p class="text-idt25" data-id="213">图 11 齿轮箱数据存储格式</p><p class="text-idt25" data-id="214">数据的存入与读取都是依赖于 Java的一个外部包 mysql- connector- java. jar（ JDBC），导入至本地项目后可以调用 JDBC中的内置类，通过实例化一个数据库连接对象进行数据的存取。为了封装驱动，连接，会话等 JDBC内容，新建了一个 Mysql_ Connect类提供数据库连接( Connect())，会话( getStatement())，断开连接( Dis_ Connect())三个数据库常用的功能。</p><p class="text-idt25" data-id="215">存储的过程中，由于数据量的问题，如果采用单条记录提交一次的方式进行两百万条数据的存储，那么一共需要两个小时，但是采用 JDBC自带的批处理操作 Batch，可以将这个时间减少一半。具体操作如下：</p><p class="text-idt25" data-id="216">String INSERT = getInsertQuery(id， Name， line); statement.addBatch(INSERT); id++; count++; //执行批量执行 if (count]40000) {  statement.executeBatch();  count = 0; }</p><p class="text-idt25" data-id="217">通过批处理操作，每一次与数据库的交互都能提交四万条数据，可以极大地减少Mysql连接，认证等的时间花销，提高存储效率。</p><p class="text-idt25" data-id="218">而读取数据的时候，由于Decision Tree算法与Support Vector Machine算法需要的数据结构不同，所以定义了两个数据读取类，分别为：ReadData.java与SVMReadData.java，在ReadData.java中定义了静态方法getSelectQuery()提供给所有需要生成查询语句的类调用。</p><p class="text-idt25" data-id="219">另外每一个数据库读取类都提供了 readTrainData()和 readTestData()两类读取方式，提供给用户有选择的从数据库中读取出指定数量大小的数据记录。</p><p class="text-idt25" data-id="220">数据读取的时候还需要一个Parameter类进行辅助，在这个类里面可以定义训练集与验证机的比例，训练集或者验证集的大小。每一个Parameter类内部定义了静态变量：训练样本数，测试样本数，以及二者之间的比例三个变量值。三者之间相互调节，并且因为静态变量的特性作用于全局。这样做的好处是不论在项目中定义多少个 Parameter实例化对象，只需要在任意处调用调节方法进行修改，就可以直接作用于全局，保证不同方案之间的数据量一致性。</p><p class="text-idt25" data-id="221">3.3 决策树实现</p><p class="text-idt25" data-id="222">3.3.1 连续属性值离散化</p><p class="text-idt25" data-id="223">因为获取的数据为浮点数表示的连续值，如果给每个取值开一个分支显然不可行，就算是将精度降低到0.1，那么五个属性延展开来最后还是会超过上亿种分支的可能，显然这个数量级对于分类问题是很不友好的，所以在进行分类之前需要进行数值离散化处理。</p><p class="text-idt25" data-id="224">离散化常用方法为二分法。给定样本集D与连续属性a，二分法试图找到一个划分点t将样本集D在属性a上分为a t与a ＞ t。但是这一点对于我们的数据规模和跨度不合适，所以采用一种基于熵的离散化方法[11]。</p><p class="text-idt25" data-id="225">当频率（或概率）分布具有最大的属性值个数时，熵（或信息）被最大化[12]。当我们单独将某一个属性所有的值与对应的分类结果拿出来做一个单属性样本集 X的时候，我们可以自定义若干个区间对属性进行区间分割，然后根据前面的信息熵的计算公式，计算出这个样本集的信息熵 H( X)。另外根据凸函数的性质：</p><p class="text-idt25" data-id="226">由参考文献中提到的离散化算法（ EADC），可以将每个连续属性离散化为若干区间，区间数目由数据本身决定（但是最小区间划分数目为10个），之后找到合并两个区间后使得合并前后熵差最小，然后保存划分点，继续合并直到达到最佳平衡为止。是否达到最佳平衡的度量公式为：</p><p class="text-idt25" data-id="227">式中，kmax表示最大区间数，Hmax(p)表示最大熵值。在实际操作中，对其进行简化，取40个划分区间下的对应值。</p><p class="text-idt25" data-id="228">连续属性离散化之前，决策树的数据精度设置为1，正确率一直在30%左右；离散化后，数据精度设置为0.1，正确率随着训练数据量增长而增长。训练数据量为1000条左右时正确率为35%左右，当数据量提升到20000条左右时，准确率有53%左右，而 SVM数据因为不需要划分区间，所以正确率的增长与数据量的线性关系并不明显，从1000条数据到两万条数据仅仅波动了1%的正确率不到。可见决策树的正确率在初期更加依赖于训练数据量的积累。</p><p class="text-idt25" data-id="229">整个离散化的过程如下：</p><p class="text-idt25" data-id="230">从数据库读取数据，传入到离散化方法中；</p><p class="text-idt25" data-id="231">先针对单一的属性，取出所有的值，并且对其进行排序；</p><p class="text-idt25" data-id="232">排序后划分区间，并且利用熵的计算公式计算出初始熵，设置度量数值Ck = 0 ；</p><p class="text-idt25" data-id="233">合并两个相邻区间，使合并前后的熵差最小，并且重置划分点，保存合并后的熵值；</p><p class="text-idt25" data-id="234">根据上面的度量公式计算出Ck-1 = h；</p><p class="text-idt25" data-id="235">如果Ck-1 ] Ck ，那么k = k -1，Ck ] Ck-1 ，回到第(4)步；</p><p class="text-idt25" data-id="236">如果Ck-1 [ Ck ，保存当前的区间划分，结束区间划分进程；</p><p class="text-idt25" data-id="237">将传入的数据根据当前区间划分进行离散化处理。</p><p class="text-idt25" data-id="238">离散化流程图如下：</p><p class="text-idt25" data-id="239">图10 连续属性离散化流程图</p><p class="text-idt25" data-id="240">3.3.2 样本初始化</p><p class="text-idt25" data-id="241">决策树的核心算法是ID3算法，其他的数据结构，数据处理等都是辅助内容，但是样本初始化在整个体系中也是举足轻重的。</p><p class="text-idt25" data-id="242">首先定义属性名列表 attribute，也就是四个传感器的位置和负载百分比，然后是在此基础上增加一个分类属性名重新定义一个列表 attributr_ Names，作为读取数据库内容时候的列名：</p><p class="text-idt25" data-id="243">String[] attribute = new String[] {”Sensor1”，”Sensor2”，”Sensor3”， ”Sensor4”， ”Load”}; String[] attribute_ Names= new String[]{” Sensor1”，” Sensor2”，” Sensor3”，” Sensor4”，” Load”，” category”};</p><p class="text-idt25" data-id="244">当属性列表定义完毕之后，就会进入Decision Tree算法的样本读取方法，readSample()。在这个方法中，通过在前面数据库模块定义的ReadData类中的readTrainData()方法读取出数据之后进行样本整合。具体的操作为：</p><p class="text-idt25" data-id="245">定义一个Sample类，内含属性名及其对应的属性值；</p><p class="text-idt25" data-id="246">对读取出来的二维数组逐行读取，每一行定义为一个Sample实例；</p><p class="text-idt25" data-id="247">按照所有实例的分类，定义与分类数目相同的链表，读取当前样本的分类，并且将当前Sample添加到相应的链表上去。如果没有这个分类，就新添加一条链表。</p><p class="text-idt25" data-id="248">最后返回的数据结构为类别为键，包涵所有此类样本的链表为值的键值对Map。</p><p class="text-idt25" data-id="249">样本初始化整体流程如下：</p><p class="text-idt25" data-id="250">图12 样本初始化流程图</p><p class="text-idt25" data-id="251">3.3.3 生成决策树</p><p class="text-idt25" data-id="252">在样本初始化完毕后，就进入生成决策树的阶段。调用定义的generateDecisionTree()方法，传入样本集和属性列表。就可以得到一颗基于此样本集，用ID3算法构建的故障树了。</p><p class="text-idt25" data-id="253">//生成决策树 Object decisionTree = generateDecisionTree(samples，attribute);</p><p class="text-idt25" data-id="254">在这个方法当中，ID3算法担任了求出信息增益最大的属性的责任。整个generateDecisionTree()方法采用递归的方式，不断地向下延伸分支，直到将当前节点归类为叶节点才会停止。</p><p class="text-idt25" data-id="255">流程解释如下；</p><p class="text-idt25" data-id="256">（1） 判断是否当前分支的样本数目，如果为空或者分类只有一种，那么将当前样本的类别作为叶节点的分类；</p><p class="text-idt25" data-id="257">（2） 如果属性用完，或者是同一个属性值对应的样本子集中无法通过数目将此节点归类，那么采用后验分布进行归类；</p><p class="text-idt25" data-id="258">（3）如果上述条件都不满足，那么就使用 ID3算法计算出当前的分支属性，并且读取该分支属性的各个属性值构成分支向下延伸（进入递归），直到遇到上述的条件成为叶节点为止；</p><p class="text-idt25" data-id="259">（4） 当满足生成叶节点的条件，则递归止步于当前节点，返回至其父节点，直至抵达根节点为止。</p><p class="text-idt25" data-id="260">整体流程如下：</p><p class="text-idt25" data-id="261">图13 决策树生成流程示意图</p><p class="text-idt25" data-id="262">至此，整个决策树就已经训练完毕了。我们从这一系列的操作中得到了一个Tree类的实例对象。每一个Tree都是由一个根节点和一系列的分支组成，除了叶节点不是Tree类型外，其他的子节点都是Tree类型。这一点也为我们提供了一个良好的搜索环境。只要检测当前节点是否为Tree类型，就可以判定是否已经搜索到了子节点了，这一特性在后面的数据测试中将会用到。</p><p class="text-idt25" data-id="263">而在上面生成决策树时用到的ID3方法，下面进行详细的解释：</p><p class="text-idt25" data-id="264">传入一个样本集，一个属性列表；</p><p class="text-idt25" data-id="265">样本集形式为分类与此分类对应的所有样本，注意此处为分类而不是属性值；</p><p class="text-idt25" data-id="266">对每一个属性值进行信息增益的计算，具体的实现方式为：</p><p class="text-idt25" data-id="267">读取当前属性值，拿到一个键值对， 所属类别--]样本集</p><p class="text-idt25" data-id="268">解析键值对，分解出key和value，其中key为类别，value为此类别所有的样本</p><p class="text-idt25" data-id="269">对于Value里边读出来的每个样本，分别读取当前属性下的值，然后建立起来当前属性值相同的所有样本的样本集；</p><p class="text-idt25" data-id="270">建立起了所有属性值对应的样本子集后，再在此样本子集的基础上按照分类的不同进行子集划分，相当于是二次划分样本集；</p><p class="text-idt25" data-id="271">最终得到的数据结构如下：</p><p class="text-idt25" data-id="272">图14 ID3信息增益计算的数据结构</p><p class="text-idt25" data-id="273">根据上面的数据结构，计算每一个属性值的信息熵，然后结合所有的属性值计算出这个属性所对应的信息增益，最后得到信息增益最大的那个属性，即可将此属性的下标，对应的信息增益以及由这个属性所衍生出来的样本集打包成一个数组返回。</p><p class="text-idt25" data-id="274">至此，ID3算法执行完毕，返回一个数组供generateDecisionTree()方法选择下一个分支的属性，并且递归调用自身产生子树分支。</p><p class="text-idt25" data-id="275">3.3.4 数据测试类</p><p class="text-idt25" data-id="276">数据测试类接受一个模型obj，一个属性名列表Attr_Name，一个测试数据（属性值）列表TestData，这三个参数用于测试数据；另外由于需要对外开放测试结果，还接受一个字符串变量line用于递归返回最终结果。下面是TestData.java的定义：</p><p class="text-idt25" data-id="277">public static String TestData(Object obj， Object[] Attr_Name， Object[] TestData，String line) {</p><p class="text-idt25" data-id="278">基于既定的决策树模型，从根节点出发，根据传入的测试数据选择分支，一路向下，直到抵达叶节点，或者无法找到向下的分支为止。流程解释如下：</p><p class="text-idt25" data-id="279">判断传入的obj类型是否为Tree，如果不为Tree，代表着已经到了叶节点，可以根据当前节点的值来找到对应的分类；</p><p class="text-idt25" data-id="280">如果 obj是 Tree类型，找到 obj对应的属性名，然后根据属性名找到测试数据的值，同时新建立一个未曾使用的属性名列表和对应的测试数据列表（长度等于原来的列表减一）；</p><p class="text-idt25" data-id="281">遍历当前节点的每个分支，找到属性值等于测试数据的那一条；</p><p class="text-idt25" data-id="282">将分支对应的子树以及（2）中建立的两个新列表，还有line传入新的TestData()中，递归调用，返回line；</p><p class="text-idt25" data-id="283">数据测试类被定义为静态类，所以可以直接在GUI后台程序中调用而不用考虑是否定义实例。在GUI中的命令处理环节，有两个部分运用到了TestData()这个方法，一个是test，这个命令可以单独对一组数据进行测试；而另外一个autotest则是对已经加载好的数据测试文件进行解读后，直接批量测试，最后得出准确率，结合SVM下的准确率一起显示在消息提示栏。每一次测试数据的整体流程图如下：</p><p class="text-idt25" data-id="284">图15 数据测试流程</p><p class="text-idt25" data-id="285">3.4 支持向量机实现</p><p class="text-idt25" data-id="286">SVM由于其复杂性较高，而且网络上已经有了相当成熟的软件包可以直接取用，所以我最后借鉴了台湾大学林智仁教授的LibSVM包中的Java部分。</p><p class="text-idt25" data-id="287">这个包的对外内容由四个，分别是svm_toy，svm_scale，svm_train，svm_predict。我用到的是后面两个svm_train 和 svm_predict。其中svm_train是训练模型用到的实现代码，svm_predict是在实际使用过程中使用模型进行数据分类的实现代码。</p><p class="text-idt25" data-id="288">为了配合GUI的显示，将这些内容整合到了一个类：ZZB_SVM.java中，确保可以全面的调用这些包内的方法并且返回需要的数值。代码如下：</p><p class="text-idt25" data-id="289">import java.io.IOException; import java.text.NumberFormat;  public class ZZB_SVM {  public static Float main() throws IOException {  SVMReadData sr = new SVMReadData();  Parameter par = new Parameter();  String trainFileName = sr.readTrainData(par);  String testFileName = sr.readTestData(par);  //训练使用的数据以及训练得出生成的模型文件名。  String[] trainFile = { trainFileName， ”model.txt” };  //测试数据文件，模型文件，结果存放文件  String[] predictFile = { testFileName， ”model.txt”，”predict.txt” };  System.out.println(”........SVM Start..........”);  long start=System.currentTimeMillis();  svm_train.main(trainFile); //训练  System.out.println(”Usage of Time : ”+(System.currentTimeMillis()-start));  //预测  float x = svm_predict.main(predictFile);  return x;  }</p><p class="text-idt25" data-id="290">该类的main()方法最终将返回一个测试正确率的浮点数。静态方法main()的调用位置在人机交互界面类GUI.java中调用并且显示。</p><p class="text-idt25" data-id="291">在对LibSVM的使用过程中，均使用默认的选项进行模型训练。下面是对于SVM分类建模过程有较大影响的参数解释：</p><p class="text-idt25" data-id="292">SVM类型设置（SVM type）：默认为C-支持向量分类机，参数C是惩罚系数，C的数值与对错误分类的惩罚成正比例关系。因此，惩罚系数对于模型预测的精度有较大的影响；</p><p class="text-idt25" data-id="293">核函数设置（kernel type）：默认为径向基函数 (Radial Basis Function，简称为RBF函数)，在本次试验中采用高斯核函数，见表2-1中第三条；</p><p class="text-idt25" data-id="294">gamma：核函数中的gamma函数设置，此背景下默认为0.25；</p><p class="text-idt25" data-id="295">eps：允许的终止判据，类似迭代精度(默认0.001)</p><p class="text-idt25" data-id="296">shrinking：是否使用启发式，0或1(默认为1)</p><p class="text-idt25" data-id="297">3.5 人机交互界面设计</p><p class="text-idt25" data-id="298">人机交互界面采用一个名为GUI.java的类来实现，其采用Java的awt和Swing两个专用于GUI编程的自带库来实现各个组件。在 ZZB_ JCS. java的 main方法中定义一个 GUI. java的实例化对象后，其以线程的方式独立于主线程存在，不过在主线程运行完毕之前会将构建的决策树模型以及其他一些会在人机交互中用到的变量，通过定义的静态方法传入到 GUI的实例对象中，从而实现从后台到前台的过渡。</p><p class="text-idt25" data-id="299">GUI整体由一个大框架，12个Label文字标签、1个文字输入栏，3个按钮组成。初步效果如下：</p><p class="text-idt25" data-id="300">图15 人机交互界面展示</p><p class="text-idt25" data-id="301">另外配有两个菜单栏提供功能显示：</p><p class="text-idt25" data-id="302">图16 菜单栏</p><p class="text-idt25" data-id="303">3.5.1 界面组件介绍</p><p class="text-idt25" data-id="304">在主程序的后半段，会将决策树算法处理数据后生成的决策树模型传入到 GUI线程实例中，然后在此基础上，将决策树模型分段在 GUI上展示。Line1-Line10就是用于展示决策树模型的。最上方的This is the Code Line for Command！作为提示，表示下面的输入框的作用。在文本输入框中键入对应的指令即可调用不同的系统命令执行包括测试数据，自动加载测试数据，退出，决策树展示换行等不同的功能。部分命令按钮会在首次加载GUI的时候以弹窗形式告知。</p><p class="text-idt25" data-id="305">图16 初始化人机交互指令提示弹窗</p><p class="text-idt25" data-id="306">按照提示，在命令框中输入HELP会显示所有的命令：</p><p class="text-idt25" data-id="307">图17 help命令弹窗</p><p class="text-idt25" data-id="308">底部的两个按钮则是用于查看决策树模型的辅助按钮。Button-CLEAR用于直接清空Label的输出，恢复到模型展示初始状态，也就是初始化的时候的样子，效果等同于在命令输入框输入clear这条指令。而Button-NEXT则是等同于在命令框输入next这条指令的效果，调取下一个十行决策树模型展示。</p><p class="text-idt25" data-id="309">在最底部还有一个Label，这个Label用于响应如test，Load等无法直接在界面组件上展示效果的各种命令。如果命令错误，那么在底部会显示Error报错；如果是进行数据测试，那么会在最后这一条Label上展示出结果；如果是如加载数据的Load指令，则会在底部显示加载结果。</p><p class="text-idt25" data-id="310">3.5.2 操作命令介绍</p><p class="text-idt25" data-id="311">下面解释下输入框能够接受的几条定义的命令：</p><p class="text-idt25" data-id="312">init：初始化决策树输出，内部加载数据，在init执行前所有的其他命令都无法操作；</p><p class="text-idt25" data-id="313">clear：清屏效果，将Line1-Line10以及底部提示栏还原为初始状态；</p><p class="text-idt25" data-id="314">next：读取下一个十行决策树内容显示在界面上；</p><p class="text-idt25" data-id="315">last: 读取上一个十行决策树内容显示在界面上；</p><p class="text-idt25" data-id="316">test [data(value1 value2 value3 )]：调用决策树模型测试输入的数据：数据格式如上。如果没有在命令框中输入数据，那么系统会查询是否已经加载了外部数据，如果有，则自动读取外部数据，否则按照预设的数据（固定的示例）进行计算演示；其结果输出到底部消息提示栏的为分类结果；</p><p class="text-idt25" data-id="317">load: 效果类似于菜单栏的open</p><p class="text-idt25" data-id="318">autoload：自动加载测试数据；搜索当前目录下的测试数据文本，如果要跨越目录可以使用左上角的菜单栏-]Open，选择文件读入或者在命令框中输入LOAD加载文件读取窗口；</p><p class="text-idt25" data-id="319">autotest：自动将目前存储的所有测试数据进行分类预测，并且统计正确率。同时调用ZZB_SVM.main()测试SVM下的结果，将两种模型准确度输出到底部消息提示栏；</p><p class="text-idt25" data-id="320">save：将当前的决策树存入到指定文件夹，效果等同于菜单栏中的save选项；</p><p class="text-idt25" data-id="321">help：输入后可以跳出弹窗显示所有命令提示；</p><p class="text-idt25" data-id="322">showinfo：显示当先使用者的信息，包括工作目录、使用者、操作系统、训练集大小、测试集大小、模型输出行数、页面数等；</p><p class="text-idt25" data-id="323">exit：退出GUI界面，效果等同于默认的退出按钮或菜单栏的exit选项；</p><p class="text-idt25" data-id="324">settrainnum：设置训练集大小，后必须跟一个整形参数，另外重置后必须再次进行初始化，否则会报错；</p><p class="text-idt25" data-id="325">settestnum：设置测试集大小，后必须跟一个整形参数，重置后也必须进行初始化操作。</p><p class="text-idt25" data-id="326">3.5.3 适用场景</p><p class="text-idt25" data-id="327">此GUI界面适用于智能工厂环境，因为需要预装数据库，Java8软件，所以需要电脑的性能较好，才能保证我们能够迅速得到模型并且初始化GUI界面。另外GUI界面需要标准键盘输入才能与之交互，如果可以使用一些实物按钮来封装命令或者对应着GUI界面上的某些按钮将会有较好的效果。</p><p class="text-idt25" data-id="328">每一次运行都是从主程序开始运行。因为该模型属于数据驱动方式，所以每一次模型的建立都依赖于历史运行数据。同时测试数据的时候也需要在本地读取一份需要测试的数据集，而且要根据相应的格式存储。所以我们需要用PLC、Arduino或者树莓派等控制器接受来自传感器的数据之后，进行简单的处理再存储到本地或者是串口发送到PC端。当然也可以将这份数据处理的工作放到运行程序的PC上，不过这样的话负载不够均衡。</p><p class="text-idt25" data-id="329">在我的设计中，由于无法进行实物制作，所以 PC需要从 Mysql动态读取数据，如果直接使用的话，中间还存在一个数据转储的问题，这对于网络资源、运算能力都是极大地浪费。所以在实际的操作中完全可以用串口或者是局域网将控制器和PC进行连接，然后由PC端接收后直接使用即可。</p><p class="text-idt25" data-id="330">图18 应用场景示意图</p><p class="text-idt25" data-id="331">另外，我们也可以将所有程序打包发布为 EXE可执行文件，安装到本地后直接使用而不用去部署环境，而且可以根据工厂里面的设备导出不同类型的可执行文件，适配于大部分的生产场合。</p><p class="text-idt25" data-id="332">4 性能分析</p><p class="text-idt25" data-id="333">4.1 性能度量</p><p class="text-idt25" data-id="334">本次设计采用了两套方案，我们就需要评估方法来对性能进行评估以便我们选择更好的模型构建方式。性能测试采用测试集来测试模型对于新样本的分类能力。最后以测试集上的误差来作为实际误差的近似。</p><p class="text-idt25" data-id="335">测试集的获取的方式有几种，本次采用留出法。即将一个样本集 D划分为两个，一个作为模型训练集 S，一个作为模型测试集 T，满足 D= ST且 ST=，常见的划分方式为分层抽样数据后取出三分之一到五分之一作为测试集。这一点模型通过Parameter这个类中的静态变量来定义。</p><p class="text-idt25" data-id="336">private static int rate = 2; private static int trainNum = 20000; private static int testNum = trainNum/rate;</p><p class="text-idt25" data-id="337">所有的数据数量都来自于这个类中的静态变量。</p><p class="text-idt25" data-id="338">在GUI界面中提供了autotest进行批量的数据测试，最终结果显示在消息栏。里面有DecisionTree的精度和SVM的精度表示。而由 错误率+精度=1 就可以知道错误率。</p><p class="text-idt25" data-id="339">另外，还引入查准率（precision）P和查全率（recall）R的概念。对于二分类问题，分类结果的混淆矩阵和上述两种概念的定义如下：</p><p class="text-idt25" data-id="340">表3-1 混淆矩阵</p><p class="text-idt25" data-id="341">真实情况</p><p class="text-idt25" data-id="342">预测结果</p><p class="text-idt25" data-id="343">正例</p><p class="text-idt25" data-id="344">反例</p><p class="text-idt25" data-id="345">正例</p><p class="text-idt25" data-id="346">TP（真正例）</p><p class="text-idt25" data-id="347">FN（假反例）</p><p class="text-idt25" data-id="348">反例</p><p class="text-idt25" data-id="349">FP（假正例）</p><p class="text-idt25" data-id="350">TN（真反例）</p><p class="text-idt25" data-id="351">查全率P定义：</p><p class="text-idt25" data-id="352">查准率R定义：</p><p class="text-idt25" data-id="353">4.2 决策树性能度量</p><p class="text-idt25" data-id="354">决策树的精度对数据数量很敏感，数据量少的时候精度较低，数据量提升之后精度会随之提高。而SVM则对数据的数量要求较低，在连续属性离散化的部分曾介绍过。下面是用各种大小的训练数据量下得出来的数据量-精度图：</p><p class="text-idt25" data-id="355">图20 决策树数据量-精度关系图</p><p class="text-idt25" data-id="356">下图中分别显示了精度（Accuracy）、查全率（Precision）、查准率（Recall）在各种数据下的对应值。</p><p class="text-idt25" data-id="357">图21 三种度量与数据量的关系图</p><p class="text-idt25" data-id="358">从两图分析可知：</p><p class="text-idt25" data-id="359">整体上决策树的预测结果精度与数据量有关，据趋势可以看出来，数据量越大，预测精度就会越高；</p><p class="text-idt25" data-id="360">数据量与查全率的关系不大，查全率是尽可能将更多的情况考虑到的数值度量；</p><p class="text-idt25" data-id="361">可以看到查准率随着数据量的提高甚至略有下降趋势，查准率表示对预测结果正确性要求的度量；</p><p class="text-idt25" data-id="362">在数据量较大的时候，查全率与查准率二者之间会产生矛盾。如果希望将大部分的正例都选出来，那么可以通过提高选取的样本数量提高来实现，但是这样的话就会使得查准率降低，如我们上面图形中所示；而如果希望查准率高，那么就尽量让选中正例的范围变大，因为我们有连续属性离散化的过程，所以当数据较多时，离散化区间较多，区间细分程度更高，以至于查准率会稍有降低。</p><p class="text-idt25" data-id="363">4.3 支持向量机性能度量</p><p class="text-idt25" data-id="364">支持向量机的性能度量主要是精度，在运行时间上SVM比决策树同等数据量规模下所花费的时间更多，所以主要对比二者之间的精度。</p><p class="text-idt25" data-id="365">相比于决策树，SVM显然受数据量的规模影响小得多，而且SVM由于其本身性质，对于错误数据的敏感程度取决于惩罚系数的大小。所以哪怕错误的数据不是很多，在很多情况下也会造成较大的影响。</p><p class="text-idt25" data-id="366">下面是SVM的精度与数据量的关系图：</p><p class="text-idt25" data-id="367">图21 SVM 数据量-精度图</p><p class="text-idt25" data-id="368">从图中分析，对比决策树从30%~60%的波动， SVM50%~60%的精度波动范围显然受数据量的影响较小，但是从整体趋势上看， SVM的精度也会随着数据量的增大微弱的提高。</p><p class="text-idt25" data-id="369">5 结论</p><p class="text-idt25" data-id="370">5.1 全文总结</p><p class="text-idt25" data-id="371">本次设计内容总体达到了预期进度，成功的建立了故障诊断的模型和人工交互界面。并且通过划分训练集和测试集，实现了对故障或者异常情况的推理。</p><p class="text-idt25" data-id="372">本次设计所采用的数据均为连续性数据，在支持向量机的模型中影响不大， 但是对于决策树模型的精度影响十分之大。后来经过EADC算法的离散化处理，决策树模型的精度有了很大的进步。而且在性能分析中提到：决策树对于数据量十分敏感，在运行环境的最大承载能力下，决策树的精度能达到58%左右，而且上升趋势仍然十分明显。由此可见如果将决策树模型应用于实际生产环境，辅之以足够的运算能力，也会有一定的实际应用价值。同时因为模型的计算过程较快，所以数据的更新迭代可以周期性的展开，确保数据驱动所使用的数据都是近期的历史数据，紧随着生产设备的实际情况而更新。不用过多的拘泥于过往的先验知识。</p><p class="text-idt25" data-id="373">当然，基于数据驱动模型的缺陷也是显而易见的：对于未曾出现过的故障类型或者是异常数据，就会有无法处理或者是判定错误的现象，在这一点上钟福磊的混合故障诊断模型显然更加具有实用性。</p><p class="text-idt25" data-id="374">另外借鉴与LibSVM的支持向量机模型由于其集成度很高，内部相当完善，所以在数据量的变化过程中具有较好的表现。但是由于其在运算时所需要的时间与内存等相较于决策树模型更多，而且其精度与数据量的关系远没有决策树那么明显。</p><p class="text-idt25" data-id="375">所以在实际的应用中，决策树适合于数据量较大，对于精度要求高，易于理解的场合中。而且本次设计的GUI界面配套了决策树的输出，利于操作人员理解使用。而SVM更加适合于数据量较小，但是对于精度有一定要求的场合。</p><p class="text-idt25" data-id="376">5.2 展望</p><p class="text-idt25" data-id="377">本次毕设过程中，我学习到了很多的知识，尤其是对于算法实现，数据选取，数据挖掘，模型优化等内容有了长足的认识与进步。而在模型建立过程中，还有很多理论和技术上的问题需要解决：</p><p class="text-idt25" data-id="378">本次设计对于各个属性的选取并未经过严格考虑，在实际应用中应该提前对数据进行筛选和清理，比如计算各个属性参数之间的关联度剔除一些很明显的错误训练样本和验证样本，这样不仅能降低训练、测试开销，而且还能提高模型的预测精度；</p><p class="text-idt25" data-id="379">对于模型的处理问题，剪枝方法未曾实现，而且剪枝虽然能提高模型对一些特定数据的精度并且减少预测开销，但是在一定程度上也限制了被剪枝模型对于更大范围数据的分类能力；</p><p class="text-idt25" data-id="380">另外，在数据获取部分，应该使用一些机械方面的预备知识，对数据检测模块进行优化，使得获得的数据在计算关联度之前就先天利于模型构建；</p><p class="text-idt25" data-id="381">SVM模块的内容并未深入，参数均采用默认类型。在实际使用时，可以调节一些参数，使得支持向量机模型更加适合于不同的工作环境；</p><p class="text-idt25" data-id="382">GUI的功能可以进行扩充，同时改进人机交互体验；</p><p class="text-idt25" data-id="383">Java与Mysql的使用在设计过程中还有待改进与优化的余地。</p><p class="text-idt25" data-id="384">如果完成了上面所述的内容，配合基于数据驱动的模型只需提前设置好规范的数据格式即可适应于各类环境的特性，相信构建的模型会具有更大的实用价值。</p><p class="text-idt25" data-id="385">致谢</p><p class="text-idt25" data-id="386">光阴荏苒，四年大学生活即将走进尾声。这四年内我收获良多，对于那些曾给予我帮助，或者引领我走上正确的道路的人，我内心深处抱以深深的感激之情。</p><p class="text-idt25" data-id="387">首先需要感谢的是我的指导老师金海教授，感谢老师为我选择的课题以及对我的信任。论’lun成茓 溠茚 在我人生中最为迷茫的时候，金老师给了我莫大支持，让我坚定了走下去的信念。每一次与金老师的沟通，总能让人感觉如沐春风，感念至深，心头的不安与忐忑消失殆尽。未来几年内能够师从金老师，我感到非常幸运，也一定会严格要求自身，尽职尽责完成学业与任务！</p><p class="text-idt25" data-id="388">同时也要感谢机械学院吴波教授，虽然我们交流甚少，但是与吴波老师的沟通也十分愉快。</p><p class="text-idt25" data-id="389">另外还要感谢开题答辩时的指导老师胡友民老师，他当时一阵见血的指出我的不足之处，点名了我后期要努力的方向。这给了当时对于课题稍有不解的我一些可行的建议，十分感谢！</p><p class="text-idt25" data-id="390">还要感谢我的室友方舟同学，因为跨院系，所以很多消息都是通过他来给我解答，在我的论文写作过程中他也给予了我相当大的支持，让我规避了很多常识性的错误。另外，感谢他在后期对大纲结构，论文格式的指点，让我省下了很多时间。</p><p class="text-idt25" data-id="391">最后要感谢的是我的父母，感谢他们无私的支持，以及最长久的陪伴，感谢他们用双手，勤苦工作二十余年，为我创造了一个安然成长的环境。身处武汉异地求学，碰到过这样那样的挫折，心情潮涨潮落起伏不定，但是他们始终是我最坚实的后盾，让我可以在求学路上大步前行无需顾及身后，因为我知道他们一直都在！在未来，我一定更加勤奋的学习，不辜负父母对我的殷切期盼，争取早日成为家中顶梁柱，让父母放下身上的重担，享受生活！</p><p class="text-idt25" data-id="392">参考文献 (黑体小2号加粗居中)</p><p class="text-idt25" data-id="393">钟福磊. 工业大数据环境下的混合故障诊断模型研究[D].西安电子科技大学，2015.</p><p class="text-idt25" data-id="394">卫凤林，董建，张群.《工业大数据白皮书(2017版)》解读[J].信息技术与标准化，2017(04):13-17.</p><p class="text-idt25" data-id="395">王建民.工业大数据技术[J].电信网技术，2016(08):1-5.</p><p class="text-idt25" data-id="396">张鹏. 基于卡尔曼滤波的航空发动机故障诊断技术研究[D]. 南京: 南京航空航天大学， 2009.  </p><p class="text-idt25" data-id="397">徐德民， 刘富樯， 张立川等. 基于改进连续-离散无迹卡尔曼滤波的水下航行器故障诊断 [J]. 西北工业大学学报， 2014， 32(5): 756-760.  </p><p class="text-idt25" data-id="398">鲁峰， 黄金泉， 孔祥天. 基于变权重最小二乘法的发动机气路故障诊断[J]. 航空动力学 报， 2011， 26(10): 2376-2381.</p><p class="text-idt25" data-id="399">Frank P M. Fault diagnosis in dynamics systems using ana-lytical and knowledge-based redundancy: a survey and some new results[J]. Automatica， 1990， 26(3): 459-474.</p><p class="text-idt25" data-id="400">Reis M S， Gins G. Industrial Process Monitoring in the Big Data/Industry 4.0 Era: From Detection， to Diagnosis， to Prognosis[J]. Processes， 2017， 5(3): 35.</p><p class="text-idt25" data-id="401">张媛.采用数据挖掘技术中ID3决策树算法分析学生成绩[J].科技信息，2009(06):537</p><p class="text-idt25" data-id="402">周志华 著.机器学习， 北京: 清华大学出版社， 2016年1月. (ISBN 978-7-302-206853-6)</p><p class="text-idt25" data-id="403">贺跃，郑建军，朱蕾.一种基于熵的连续属性离散化算法[J].计算机应用，2005(03):637-638+651.</p><p class="text-idt25" data-id="404">COVER TM， THOMAS JA. Elements of information theory[M].New York: John Wiley Sons， 1991.</p><p class="text-idt25" data-id="405">朱霄珣. 基于支持向量机的旋转机械故障诊断与预测方法研究[D].华北电力大学，2013.</p><p class="text-idt25" data-id="406">易辉. 基于支持向量机的故障诊断及应用研究[D].南京航空航天大学，2011.</p><p class="text-idt25" data-id="407">王振华，杜宇波.基于ESMD和SVM的滚动轴承故障诊断[J].现代制造技术与装备，2018(01):122+124.</p><p class="text-idt25" data-id="408">Yang Li，Yan Qiang Li，Zhi Xue Wang. Fault Diagnosis of Automobile ECUs with Data Mining Technologies[J]. Applied Mechanics and Materials，2011，1069(40).</p><p class="text-idt25" data-id="409">Xiao Rong Cheng，Qiong Wang. An Improved ID3 Algorithm for Power Equipment in Green Power Engineering[J]. Applied Mechanics and Materials，2013，2488(340).</p><p class="text-idt25" data-id="410">Huan Huang，Natalie Baddour，Ming Liang. Bearing fault diagnosis under unknown time-varying rotational speed conditions via multiple time-frequency curve extraction[J]. Journal of Sound and Vibration，2017</p><p class="text-idt25" data-id="411">Guo Ping Li，Qing Wei Zhang，Ma Xiao. Fault Diagnosis Research of Hydraulic Excavator Based on Fault Tree and Fuzzy Neural Network[J]. Applied Mechanics and Materials，2013，2308(303).</p><p class="text-idt25" data-id="412">盛博， 邓超， 熊尧等. 基于图论的数控机床故障诊断方法[J]. 计算机集成制造系统， 2015， 06: 1559-1570.</p><p class="text-idt25" data-id="413">李晗， 萧德云. 基于数据驱动的故障诊断方法综述[J]. 控制与决策， 2011， 26(1): 1-9+16.</p><p class="text-idt25" data-id="414">刘强， 柴天佑， 秦泗钊. 基于数据和知识的工业过程监视及故障诊断综述[J]. 控制与决策， 2010， 25(6): 801-807+813.</p><p class="text-idt25" data-id="415">Zhang， Liangwei. Big Data Analytics for Fault Detection and its Application in Maintenance， 2016</p><p class="text-idt25" data-id="416">Jay Lee， Hung-An Kao， Shanhu Yang. Service innovation and smart analytics gor Industry 4.0 and big data environment[J]. Percedia CTRP， 2014， 16:3-8.</p><p class="text-idt25" data-id="417">邳文君，宫秀军.基于Hadoop架构的数据驱动的SVM并行增量学习算法[J].计算机应用，2016，36(11):3044-3049.</p><p class="text-idt25" data-id="418">赵华，苏东，乔文生.TBM主变速箱的状态监测与故障诊断[J].建筑机械化，2003(06):44-45+43.</p><p class="text-idt25" data-id="419">徐牧. 基于SVM的变压器故障诊断研究[D].安徽理工大学，2017</p><p class="text-idt25" data-id="420">罗雨滋，付兴宏.数据挖掘ID3决策树分类算法及其改进算法[J].计算机系统应用，2013，22(10):136-138+187.</p><p class="text-idt25" data-id="421">附录</p><p class="text-idt25" data-id="422">( 宋体小4号)</p>        <div class="paper-footer">
            <p>检测报告由<a href="http://www.paperpass.com/" target="_black">PaperPass</a>文献相似度检测系统生成</p>
            <p>Copyright © 2007-2018 PaperPass</p>
        </div>
    </div>

</div>
</body>
<script type="text/javascript" src="js/jquery.min.js"></script>
<script type="text/javascript" src="js/Lib.js"></script>
<script type="text/javascript">
    Report.report_id = '5afd279a0c129mxp7';
</script>
<script type="text/javascript">
    (function(System,$){
        var cache = new System.Cache(System.report_id,localStorage);
        $(function(){
            $.each(cache.get(),function(){
                $('[data-id='+this.id+']').addClass('g-font-color green').html(this.text);
            });

        });
    })(Report,jQuery);

</script>
</html>
